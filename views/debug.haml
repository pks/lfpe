- require 'zipf'
!!!
%html
  %head
    %title debug view (session ##{session_key})
  %link(rel="stylesheet" type="text/css" href="debug.css")
  %body
    %h1 debug view
    %h2 session ##{session_key}
    - if data["kbest"].empty?
      %p.red
        %strong No data to show!
    %ul
      %li
        %a{:href => "/reset", :target => "_blank"} reset progress
      %li
        %a{:href => "/reset_weights", :target => "_blank"} reset weights
      %li
        %a{:href => "/reset_extractor", :target => "_blank"} reset extractor
      %li
        %a{:href => "/reset_add_rules", :target => "_blank"} reset add. rules
      %li
        %a{:href => "/shutdown", :target => "_blank"} shutdown
      %p
        %strong learning rate:
      %select
        - [1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001,0.000000001,0.0000000001].each do |i|
          %option{:value => i, :onclick => "window.open(\"http://\"+window.location.host+\"/set_learning_rate/#{i}\");"} #{i}
      %span | sparse features:
      %select
        - [1000,100,10,1,0.1,0.01,0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001,0.000000001,0.0000000001].each do |i|
          %option{:value => i, :onclick => "window.open(\"http://\"+window.location.host+\"/set_sparse_learning_rate/#{i}\");"} #{i}
    %table
      %tr
        %td.noborder
          %strong source:
        %td.left #{data["source"]}
      %tr
        %td.noborder
          %strong post-edit:
        %td.left #{data["target"]}
      %tr
        %td.noborder
          %strong original mt:
        %td.left #{data["1best"]}
      %tr
        %td.noborder
          %strong best match (bleu=#{data["best_match_score"]}):
        %td.left #{data["best_match"]}
    %h2 meta
    %p <strong>k:</strong> #{data["samples_size"]}
    %p <strong>number of updates:</strong> #{data["num_up"]}
    %p <strong>updated features:</strong> #{data["updated_features"]}
    %p <strong>learning rate:</strong> #{data["learning_rate"]}
    %p <strong>learning rate (sparse):</strong> #{data["learning_rate_sparse"]}
    %p <strong>duration:</strong> #{data2["durations"][[data2["progress"].to_i-1].max]}ms
    %h2 k-best
    %p bleu | model score | original rank | \|e\| | translation \n features
    %p.red update needed ("any of the above hypotheses has a lower model score")
    %ol
      - kbest = []
      - data["kbest"].each { |i| x=splitpipe(i); kbest << [ x[0].to_f, x[1].to_f, x[2].to_i, x[3], x[4] ] }
      - kbest.sort! { |i,j| j[0] <=> i[0] }
      - kbest.each_with_index do |k,j|
        - b = kbest[0,j].map { |l| l[0]>k[0] && l[1]<k[1] }.include? true
        -if b
          %li.red
            %strong #{"%.2f"%(k[0].to_f*100)} | #{k[1]} | #{k[2]} | #{k[4].split.size} |#{k[4]} <br/>
            %p{:style=>"font-size:80%"} #{k[3]}
        - else
          %li
            %strong #{"%.2f"%(k[0].to_f*100)} | #{k[1]} | #{k[2]} | #{k[4].split.size} | #{k[4]} <br/>
            %p{:style=>"font-size:80%"} #{k[3]}
        - if [9,89].include? j
          %hr
    %h2 weight updates
    %table
      %tr
        %th feature
        %th before
        %th after
        %th diff
        %th raw diff
      - data["weights_before"].default = 0
      - data["weights_after"].keys.each.sort { |a,b| a[0] <=> b[0] }.each do |k|
        %tr
          %td.noborder <strong> #{k} </strong>
          %td #{"%+.3f"%data["weights_before"][k].round(4)}
          %td #{"%+.3f"%data["weights_after"][k].round(4)}
          - diff = data["weights_after"][k]-data["weights_before"][k]
          - if diff < 0
            %td.red #{"%+.3f"%(diff).round(4)}
          - elsif diff > 0
            %td.green #{"%+.3f"%(diff).round(4)}
          - else
            %td #{"%+.3f"%(diff).round(4)}
          - if !k.start_with? "R:"
            %td #{"%+.1f"%((data["weights_after"][k]-data["weights_before"][k])/data["learning_rate"]).round(2)}
          - else
            %td #{"%+.1f"%((data["weights_after"][k]-data["weights_before"][k])/data["learning_rate_sparse"]).round(2)}
    %h3 features explained
    %table
      %tr
        %td.noborder EgivenFCoherent (rule)
        %td.left -log10[ c(e, f) / sample c(f) ]
      %tr
        %td.noborder ForceRule (rule)
        %td.left only feature of additional rules, weight fixed at 1
      %tr
        %td.noborder Glue
        %td.left absolute number of rules used from glue grammar
      %tr
        %td.noborder IsSingletonF/E (rule)
        %td.left true|false (1|0) (sum)
      %tr
        %td.noborder IsSingletonFE (rule)
        %td.left true|false (1|0) (sum)
      %tr
        %td.noborder LanguageModel
        %td.left -log10[ score ]
      %tr
        %td.noborder LanguageModel_OOV
        %td.left abs. count of OOV unigrams
      %tr
        %td.noborder MaxLexFgivenE (rule)
        %td.left Sum_f -log10(maxScore) (maxScore = max_e(ttable(f))
      %tr
        %td.noborder MaxLexEgivenF (rule)
        %td.left Sum_e -log10(maxScore) (maxScore = max_f(ttable(e))
      %tr
        %td.noborder PassThrough
        %td.left absolute count of used PassThrough rules (1 per word)
      %tr
        %td.noborder SampleCountF (rule)
        %td.left log10 [ sample c(f) ]
      %tr
        %td.noborder WordPenalty
        %td.left log_10(e)*|e| = 1/log(10) * |e| (*-1) = -0.43429448190325176*|e|
      %tr
        %td.noborder SourceWordPenalty (per edge/rule)
        %td.left ^^^ (|e| <=> |f|)
      %tr
        %td.noborder R:*
        %td.left rule indicator features, sum over full derivation per rule
      %tr
        %td.noborder Shape_*
        %td.left indicator features for rule shapes
      %tr
        %td.noborder IsSupportedOnline
        %td.left counts how many rules have support from local context (Denkowski)

